<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[The only Unchanged is Change itself]]></title>
  <link href="http://liebo.github.io/atom.xml" rel="self"/>
  <link href="http://liebo.github.io/"/>
  <updated>2015-01-17T14:51:08+08:00</updated>
  <id>http://liebo.github.io/</id>
  <author>
    <name><![CDATA[liebo]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[同步并发与异步并行]]></title>
    <link href="http://liebo.github.io/blog/2015/01/17/xiao-xi-qu-dong-cai-shi-zhen-yi-bu/"/>
    <updated>2015-01-17T13:49:52+08:00</updated>
    <id>http://liebo.github.io/blog/2015/01/17/xiao-xi-qu-dong-cai-shi-zhen-yi-bu</id>
    <content type="html"><![CDATA[<blockquote><p>你在那里苦苦等待，等来的却不是你要的结果</p></blockquote>

<p>最近几天由于市场的疯狂，系统中各种隐藏的问题开始爆发，这些问题或多或少都与同步并发有关。</p>

<p>同步并发系统有两大痼疾</p>

<ol>
<li>线程池和连接池是典型同步并发：每收到一个请求，从池中取出一个线程处理业务逻辑，直到业务完成才归还线程。为了提高并发量，线程池中的线程数增加，但是线程数增加，首先占用资源大，其次业务处理过程中需要用同步锁保护数据，同步锁访问导致线程上下文切换，成为并发量的瓶颈。这个瓶颈的存在，由于系统访问量的突发高峰，系统的容量的问题便爆发了。</li>
<li>更严重的问题是，由于关键数据没有同步引起的并发逻辑问题。当今的系统，几乎都是分布式的，要想在多线程，多进程甚至多服务器并发节点间保证数据同步何其艰难，任何一个数据操作发生竞争，都将导致系统逻辑上出现错误，这种错误如果涉及到交易和账户将导致无法挽回的灾难。</li>
</ol>


<p>以上两个问题，在市场疯狂的时候同时爆发，这——不仅仅是巧合。解决的方案唯有异步并行。</p>

<p>异步并行的系统，使用自解释、自包含的消息承载数据，每一个节点的业务只需要根据消息内容即可处理，无需再访问共享数据。于是多线程，多进程，多服务器节点间无需同步，各自并行处理。</p>

<p>回调不是真正的异步。回调需要在现场保存状态，既然存在状态就可能由于竞争而导致不一致。只有消息驱动的系统才是真正的异步。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[并发模式之比较]]></title>
    <link href="http://liebo.github.io/blog/2014/09/22/bing-fa-mo-shi-zhi-bi-jiao/"/>
    <updated>2014-09-22T13:27:22+08:00</updated>
    <id>http://liebo.github.io/blog/2014/09/22/bing-fa-mo-shi-zhi-bi-jiao</id>
    <content type="html"><![CDATA[<p>前文比较过我们的应用框架和Actor模式，不过感觉仍然不够充分，所以这段时间跟进了一些常见的并发模式，发现了一些本质上的区别。</p>

<p>讲到并发计算我们常常会讲到Scala的Actor，Go的goroutine，以及erlang的process，goroutine遵循CSP（Communication Sequence Process），而Actor多少也受CSP的启发，而且这三者从外面看会有很多相似的地方，但是实际上细究起来还是有所区别的：</p>

<ol>
<li>Actor之间的通信是异步的，就是说一个Actor将消息扔到另一个Actor的Mailbox以后就不用管了，不用等待另一个Actor处理完。</li>
<li>goroutine是同步的，一个goroutine将消息扔给另一个goroutine处理，并且阻塞等待另一个goroutine处理完，才能继续。只不过，go实现了一套调度机制，可以使得goroutine可以重入而不是真正的阻塞操作系统的线程。</li>
<li>erlang的process也是异步的，不过由于erlang是一种函数式编程语言，所以不存在状态共享，是严格的无副作用。Scala则有一些把函数式编程与命令式编程糅合在一起的味道。</li>
</ol>


<p>goroutine的同步特性使得用命令式编程写起来非常简单，这也是go受热捧的原因。但是同步的通信毕竟不是一个可以很好的scale的方案，所以go在多核，分布式计算上扩展起来比较困难，相反Actor和erlang的process则轻易的做到location transparency，比如Actor可以运行在集群中的任何一个节点。</p>

<p>我们的应用框架是异步的，这一点和Actor接近，可以做到location transparency，不过有一点与以上三者都不同：</p>

<ol>
<li>我们的应用框架中，消息发送者与消费者不产生耦合，发送者只需要发出消息，由消费者去选择感兴趣的消息处理，是一种总线结构。</li>
<li>erlang和Actor中消息发送者需要知道接收者的ID，才能发送消息，是一种点对点结构。Actor也可以通过Channel解耦发送者和接收者，但是本质上每一个Actor仍然需要维护自己的一个入口消息队列。</li>
<li>goroutine使用匿名管道解偶了消息发送者和接收者，但这只是在编译器解耦，也就是不用开发者显示指定接收者ID，运行期一样产生耦合，因为毕竟是同步调用，还是点对点结构。</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[交易中间件——为何不使用Akka]]></title>
    <link href="http://liebo.github.io/blog/2014/08/17/jiao-yi-zong-xian-wei-he-bu-shi-yong-akka/"/>
    <updated>2014-08-17T15:48:28+08:00</updated>
    <id>http://liebo.github.io/blog/2014/08/17/jiao-yi-zong-xian-wei-he-bu-shi-yong-akka</id>
    <content type="html"><![CDATA[<p>我们的交易中间件所采用的容器技术与Akka的Actor模式有很大的相似性：</p>

<ul>
<li>Actor之间不共享数据，仅仅通过Immutable的消息通信，这点与我们的基于Disruptor的消息流水线是一致的。</li>
<li>Actor支持通过ZeroMQ和PGM作Pub/Sub</li>
<li>Actor甚至支持Persistence，Actor之间的通信支持Event Sourcing</li>
</ul>


<p>既然Actor如此强大，为什么我们不用其作为我们的通信基础设施和应用容器呢？主要原因是两点：</p>

<h3>一. 性能</h3>

<ul>
<li>为了达到超高的性能，基于队列的通信满足不了我们的要求，我们需要采用多播的消息总线和Disruptor作为通信手段，这类技术的一个特点是发送者和消费者之间是无耦合的，发送者只需要发送，无需了解有多少个消费者。而Akka的Actor从一开始就构成了一颗树，由父节点管理子节点，这实际上在父子节点间引入耦合，代价就是消息的传递存在额外的负担。</li>
<li>我们的设计要求使用不产生GC的内存管理方法，使用RingBuffer技术很简单就可以做到。而Akka在这一点上是不满足要求的。</li>
<li>我们的架构是非常简单的，Akka的特性远远超出了我们的需求，使用Akka当然可以完成我们的功能，但是如果需要调优的话，很可能需要对Akka进行扩展，Akka这么多特性的实现反而会成为负担。</li>
</ul>


<h3>二. 易维护</h3>

<p>Akka的Actor之间的通信是很自由的，Actor也支持动态创建，销毁，生命周期管理，甚至支持软件事务内存，这中间的逻辑实际上可以很复杂。而我们的技术从一开始就着眼于Event Sourcing + 消息流水线 这种简单的通信方式，无需这么多动态特性，无需事务。可以说我们的交互是基于服务的粗粒度的，监控和管理也是基于服务的，因而在实现上可以非常简单，简单的好处是行为可预期，出了问题也很好分析和解决，这对于金融服务来说尤其重要。</p>

<p>Akka的Actor的适用范围比我们的框架要宽广的多，这也恰恰是我们不使用Akka的原因。Akka提供的这么多灵活的特性是其最大的特点，但是对于我们这样的简单架构来说，反而会成为负担。举一个例子吧：</p>

<p>Actor的Persistence实现采用LevelDB，而我们的Event Souring实现仅仅需要通过WAL做到顺序读写就可以了，LevelDB和WAL这两个从性能上和可维护性上比较显然后者要好的多。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[基于多播的消息总线——可靠传输]]></title>
    <link href="http://liebo.github.io/blog/2014/08/02/ke-kao-chuan-shu-ack-vs-nak/"/>
    <updated>2014-08-02T10:20:57+08:00</updated>
    <id>http://liebo.github.io/blog/2014/08/02/ke-kao-chuan-shu-ack-vs-nak</id>
    <content type="html"><![CDATA[<h1>概述</h1>

<p>数据的可靠传输是任何通信基础设施必须要考虑的问题。由于数据通过网络传播要经过多种设备和中间件，所以有可能会乱序，或者丢失部分数据。一般做法是发送端将消息排序后发送，接收端按照顺序接收消息。如果发生乱序，接收端负责组装，如果发生消息丢失，发送端重发数据。</p>

<p>发送端不可以任意的往网络上发送数据，必须考虑网络的带宽，以及接收端的消费能力。为了维持发送端和接收端之间的稳定连接，接收端需要发送确认消息给发送端，有两种确认消息的方式，ACK和NAK（Negative ACK），TCP采用的是ACK，而多播则采用NAK。</p>

<h1>基于ACK的可靠传输</h1>

<p>我们先以TCP为实例看一下基于ACK的可靠传输机制，下图是图例</p>

<p><img src="http://liebo.github.io/images/reliable/test.png" alt="图例" /></p>

<p>初始状态，TCP的发送窗口大小为8，下图表示序号为0，1，2的数据已成功发送并得到接收端的确认，这些数据不用重新发送，可以从缓存中删除。而序号3，4已经发送，但还未收到确认，仍然留在缓存中。序号5至10可以发送，应用还未发送。序号11以上超出发送窗口（3-10）的范围，不可发送。</p>

<p><img src="http://liebo.github.io/images/reliable/ACK1.png" alt="初始状态" /></p>

<p>如果超过一定时间仍然没有收到3和4的确认，那么滑动窗口向左回退，于是应用重传3，4序号的数据，这便是回退n协议。回退N协议规定即使接收端收到了序列为4的数据，如果没有收到3，则只能将确认序号设为2。</p>

<p><img src="http://liebo.github.io/images/reliable/ACK2.png" alt="回退N" /></p>

<p>更高效的做法，接收端收到4立刻，确认4，而发送端在重传时只需重传序号3，这便是选择重传协议（又叫SACK）</p>

<p><img src="http://liebo.github.io/images/reliable/ACK3.png" alt="选择重传" /></p>

<p>当发送端收到序号为3的确认之后，窗口向又滑动，序号3可以从缓存中删除，序号11可以发送。</p>

<p><img src="http://liebo.github.io/images/reliable/ACK4.png" alt="右滑动" /></p>

<p>TCP之所以采用ACK的方式确认，主要目的是为了拥塞控制，因为Internet跨度大，网络传输各种因素影响较大，等到接收端的ACK之后再发送后续的数据，可以保证发送端不至于发送太多的数据占满带宽或者超出接收端的处理能力。TCP的慢启动和拥塞控制算法也都是基于ACK的，这样做是为了维护一个稳定可靠的互联网，否则很有可能有限的出口带宽被少数几台机器撑满。但是在高速网络上，TCP不够高效的问题就显露出来：</p>

<ol>
<li>高速网络上，丢包概率小，太多的ACK反而造成负担，而且发送端要等待ACK回来才能继续发送，会导致一定的时延。</li>
<li>更主要的问题，多播的情况，一个滑动窗口满足不了多个接收端可靠传输的需要。</li>
</ol>


<h1>基于NAK的可靠传输协议</h1>

<p>多播的解决方案是采用更激进的NAK协议，以下也以一个实际的例子解释：</p>

<p>如下图所示，序号0-4是已经发送的数据，而5以后都是可发送数据，窗口没有右边界，发送过的数据也会保留较长时间（甚至落地存储,即Event Sourcing）</p>

<p><img src="http://liebo.github.io/images/reliable/NACK1.png" alt="NACK1" /></p>

<p>如果发生丢包，接收端会在超时之后向发送端发送一条序号为3的NAK消息，于是序号3，4重新打开，发送端重发3，4以及以后的数据，这里还是回退N协议。</p>

<p><img src="http://liebo.github.io/images/reliable/NACK2.png" alt="NACK2" /></p>

<p>如果有多个接收端同时发送了多条NAK消息，那么有几种处理方式：</p>

<ol>
<li>取最小序号的NAK消息，这还是回退N协议</li>
<li>为每一个发送NAK消息的接收端建立一条单独的窗口，这就是分组回退协议</li>
<li>接收端的NAK消息指定哪些消息没收到，而不仅仅是一个序号，这样每一个窗口可以做有选择的重传，此即分组选择重传协议</li>
</ol>


<p>NAK协议更加激进的发送数据，只要没有收到NAK就可以发送数据，因而吞吐和时延比ACK协议会好，在高速网络上，NAK一般会比较少，所以不用担心分组回退会引起吞吐下降。即使最坏的情况，由于采用了多播，也不会比TCP多条连接的情况差。</p>

<p>在出现网络波动的情况下，或者有个别慢接收端的情况下，TCP拥有慢启动和拥塞控制算法，仍然可以保证可靠传输不丢数据。NAK协议也需要有一套相应的拥塞控制和启动算法（未完待续）。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[浅谈微服务中的分布式概念]]></title>
    <link href="http://liebo.github.io/blog/2014/07/23/qian-tan-wei-fu-wu-zhong-de-fen-bu-shi-gai-nian/"/>
    <updated>2014-07-23T21:42:26+08:00</updated>
    <id>http://liebo.github.io/blog/2014/07/23/qian-tan-wei-fu-wu-zhong-de-fen-bu-shi-gai-nian</id>
    <content type="html"><![CDATA[<p>微服务（Micro Service）与SOA都强调通过粗粒度的服务而不是细粒度的远程过程调用达到解耦的目的，但是两者也有不同，主要体现在微服务更加强调去中心化和分布式。</p>

<p>SOA倾向于指定一整套的标准涵盖消息传输，路由，转换、中心化的消息编舞（Orchestration）、业务工作流和规则引擎，试图用中心化的一个平台尝试去解决和描述各种类型的业务问题。可以说，SOA是先有平台标准，然后将业务往已有的平台规范上面套。</p>

<p>微服务则反其道而行之，以业务本身为中心，而通信则通过可重用的库，由业务开发时选择合理的。微服务不注重中心化的Orchestration，而比较青睐轻量级的Choreography，通过简单的ZeroMQ或者restful接口通信。</p>

<p>这两种方式应该说是各有千秋吧，开发能力差，业务规则比较规范的企业可以采用SOA，开发能力强，业务规则不好定制的企业则采用微服务。现在微服务比较火应该是拜云计算所赐吧。另一方面互联网的重视用户体验的思维，靠SOA这种比较厚重的框架去实现，也不现实。</p>

<p>不过实际上多数传统企业都是中心化的管理思路，根据Conway‘s Law，一个企业的组织架构往往决定了该企业研发部门，甚至项目的结构，所以这种去中心化的思维仍然是任重而道远啊。不过现实很骨感，在这个信息化的时代，不是被互联网颠覆，就是被淘汰。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[领域建模的目的]]></title>
    <link href="http://liebo.github.io/blog/2014/07/22/ling-yu-jian-mo-de-mu-de/"/>
    <updated>2014-07-22T22:03:08+08:00</updated>
    <id>http://liebo.github.io/blog/2014/07/22/ling-yu-jian-mo-de-mu-de</id>
    <content type="html"><![CDATA[<p>在表现层和数据层之间为何需要有一层中间抽象层：领域层？何不表现层直接访问数据层简单直接呢？我想目的主要有：</p>

<ol>
<li>领域建模是对业务的抽象，通过封装，继承，组合，分层等各种分析手段，将领域业务理顺，做合理的划分，从而领域建模本身就是将业务清晰的过程。</li>
<li>领域建模中抽象出来的概念名词，以及代表方法的动词，组成词汇表，有利于业务人员与开发人员沟通。</li>
<li>领域建模采用面向对象的方法，有利于逻辑的重用，和新业务的扩展。通过多态，能够通过简单的派生新的类型，使得原有的逻辑自动应用到新的业务。</li>
<li>相比于传统的基于用例的分析，领域建模站在系统本身的内在的角度，而不是系统的外在表象，因而能够分析清楚系统的内在本质，这也是领域建模相比用例驱动的开发扩展性和可维护性更强的原因。</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[敏捷开发——细粒度提交]]></title>
    <link href="http://liebo.github.io/blog/2014/07/21/min-jie-kai-fa-xi-li-du-ti-jiao/"/>
    <updated>2014-07-21T21:53:27+08:00</updated>
    <id>http://liebo.github.io/blog/2014/07/21/min-jie-kai-fa-xi-li-du-ti-jiao</id>
    <content type="html"><![CDATA[<p>敏捷开发鼓励细粒度的更新和提交代码，主要是为了将变化的成本减至最小。如果采用粗粒度更新和提交，有以下问题：</p>

<ol>
<li>由于长时间未更新代码，等到更新的时候如果发现代码集成有问题，改动的成本会更大。</li>
<li>其他提交代码的人已经转到新的任务，这时候再回来做集成打断其任务，而且因为是较长时间以前的代码，其记忆也不是很清晰。</li>
</ol>


<p>正确的做法是：</p>

<ol>
<li>任务对所有人透明，从而集成的时候不用在做额外的沟通</li>
<li>不用跨部门，可以就地集成</li>
<li>如果集成遇到问题，因为提交的代码粒度比较细，所以变化引起的改动成本不会太高</li>
</ol>


<p>二要做到以前几点，团队的组成和实践也应该符合敏捷开发的原则：</p>

<ol>
<li>团队的规模不能太大</li>
<li>故事点和任务的划分清晰，而且足够细</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[基于Java的金融应用中间件与消息总线]]></title>
    <link href="http://liebo.github.io/blog/2014/06/22/ji-yu-javade-jin-rong-jiao-yi-zhong-jian-jian-yu-xiao-xi-zong-xian/"/>
    <updated>2014-06-22T14:11:55+08:00</updated>
    <id>http://liebo.github.io/blog/2014/06/22/ji-yu-javade-jin-rong-jiao-yi-zhong-jian-jian-yu-xiao-xi-zong-xian</id>
    <content type="html"><![CDATA[<h1>概述</h1>

<p>2013年是互联网金融元年。现阶段，互联网在技术上对传统金融系统的冲击主要表现在两方面：</p>

<ul>
<li>为了支持海量用户，云计算，云存储逐渐替代传统IOE的软件和设备。集中式的架构也向分布式转变，并且允许分布式节点有不一致性的情况。</li>
<li>交易系统对一致性有较高的要求。多资产交易，高频交易等促进了能够充分利用硬件性能的消息处理框架和消息通信框架的产生和发展。</li>
</ul>


<p>对于云计算在金融系统中的应用已有不少例子，但是对于后一方面，国内相对华尔街等成熟市场来讲相对落后。我们率先在国内研发了一套应用中间件框架和消息总线系统，该系统基于Java开发，并且依托于开源的消息处理框架和消息通信基础设施，支持中间件的敏捷开发和灵活部署。该系统在保证高可用和一致性的前提下，理论上可处理达到百万量级的消息吞吐。</p>

<h1>系统架构</h1>

<h2>传统金融交易系统</h2>

<p>金融交易系统，一般分为消息中间件和应用中间件。消息中间件负责消息的路由和转发，而应用中间件则负责消息的流水线处理。传统的金融交易系统一般具有如下的架构</p>

<p><img src="http://liebo.github.io/images/finance_platform/traditional.png" title="传统金融交易系统" ></p>

<p>该架构会有以下问题：</p>

<ol>
<li>消息中间件（一般采用消息队列实现）是一个中心节点，消息首先发送到消息中间件，消息中间件根据路由配置转发。消息中间件水平扩容难度较大。</li>
<li>采用集中的数据库存储数据，保证数据一致性。数据库也是一个中心节点，会成为性能瓶颈。</li>
<li>应用中间件采用线程池处理并发请求。并发将导致不确定性，并且需要引入同步锁机制。</li>
<li>应用中间件采用冷备份，失效之后备用节点从数据库载入数据，需要较长时间。</li>
</ol>


<h2>我们的解决方案</h2>

<p>传统的高性能系统往往使用C/C++开发，而我们的解决方案使用Java开发，这是因为Java在高性能计算领域已经证明了其可行性，而Java的开发效率和庞大的社区支持是C/C++无法比拟的。</p>

<p>我们的解决方案是一种分布式的方案。首先，在网络拓扑结构上，系统具有多个服务器节点，节点通过可靠多播(ZeroMQ + OpenPGM)的消息总线发送和接收消息。所有消息可以达到任何节点，由节点本身而不是消息中间件根据消息主题和消息属性选择感兴趣的消息处理。</p>

<p><img src="http://liebo.github.io/images/finance_platform/new.png" alt="新金融系统网络拓扑" /></p>

<p>其次，节点由多个消息处理器组成的消息流水线构成。同理，消息在处理器之间的传递也是分布式的，每一个处理器根据消息主题和消息属性选择感兴趣的消息。</p>

<p><img src="http://liebo.github.io/images/finance_platform/pipeline.png" alt="应用容器消息流水线" /></p>

<p>相比传统系统，该系统具有以下优势：</p>

<ol>
<li>采用消息总线代替消息中间件，消息接收者可任意添加，水平扩容无压力。</li>
<li>排队机对消息排序，通过Event Sourcing模式保证一致性。采用WAL（Write Ahead Log）持久化，性能远高于一般数据库。</li>
<li>应用中间件采用开源的LMAX Disruptor模式实现消息流水线，基于通用硬件即可达到超高性能。开发也更简单：无需并发处理，确定性的编程模型，无需同步锁。</li>
<li>以上两点也保证了互为备份的多个应用中间件状态完全一致，可以做到双活，零延迟失效切换。</li>
</ol>


<h1>设计原则</h1>

<p>作为一个典型的实时高性能系统，我们采用了响应式（Reactive）模型。根据参考文献中的The Reactive Manifesto，一个响应式的系统的设计应该关注以下几点原则：</p>

<h2>响应事件（Reactive to Events）</h2>

<p>一个响应式系统应该是真正异步的，事件驱动的。</p>

<ul>
<li>我们的系统是一个真正的异步系统，节点/处理器之间不存在共享可变状态，所有的状态变化都通过消息在节点/处理器之间传递，处理器只处理其职责范围内的计算，没有阻塞的同步操作。</li>
<li>这个系统中，事件（消息）是一等公民，系统的设计就是抽象事件，事件处理器，设计事件路由表和事件流水线。事件消息通过消息总线在节点之间高速传递，通过消息流水线在处理器间超高速的传递。</li>
</ul>


<h2>响应伸缩（Reactive to Scale）</h2>

<p>为了可伸缩，事件处理器要做到位置透明Location transparency。</p>

<ul>
<li>在我们系统中，由于事件处理器之间无共享状态，所以事件处理器可以部署到任何一个节点，以及消息流水线的任何位置，要做的只是配置好消息路由。这保证了系统的向上伸缩（Scale up）以及向外伸缩（Scale out）。向外伸缩，只需将新服务器节点接入总线多播组，而向上伸缩，只需增加处理器的数量，并且把消息按序号进行划分。</li>
</ul>


<h2>响应错误恢复(Reactive to Resilience）</h2>

<p>响应式系统应当是鲁棒的，能够自动处理错误的。</p>

<ul>
<li>在我们系统中，应用中的错误也作为一种事件在节点和处理器之间流动，错误消息也有其自有的主题和消息类型，任何一个节点/处理器在配置路由时可以选择关心的错误消息，从而能够成为一个Supervisor角色。这个系统是否鲁棒，取决于Supervisor是否能够很好的处理错误，而发生错误的处理器不用现场处理。这实际上将应用逻辑与处理失败的逻辑隔离开来，有利于业务逻辑相对干净，而Supervisor角色则专注于治愈错误，防止错误在节点/处理器之间传递和扩散。</li>
</ul>


<h2>响应用户（Reactive to User）</h2>

<p>以上几点决定了系统可以实时响应用户操作，以此为基础可以产生丰富的用户交互模型和友好的用户体验。</p>

<h1>性能</h1>

<p>系统唯一的中心节点是排队机，因此排队机的性能也就直接决定了系统的性能。以下是对排队机的压力测试结果。</p>

<p><img src="http://liebo.github.io/images/finance_platform/performance.png" alt="排队机性能测试结果" /></p>

<p>测试使用的是两核八线程CPU，通过千兆网卡与交换机连接。测试的最高吞吐可达到35万/每秒。分析表明性能瓶颈主要在网络，使用虚拟网络接收测试表明，排队机的吞吐量可达到接近百万/每秒。接下来优化的方向主要有：</p>

<ol>
<li>使用万兆网卡，或者更高速的InfinityBand解决方案</li>
<li>使用自主研发的更轻量级的可靠多播协议代替OpenPGM</li>
</ol>


<h1>应用</h1>

<p>该系统逐步应用于交易，风控，做市策略系统。以下以策略系统的消息流水线配置为例其阐述系统的应用。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;stage</span> <span class="na">plugin=</span><span class="s">&quot;bus&quot;</span> <span class="na">processor=</span><span class="s">&quot;recv&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'><span class="nt">&lt;stage</span> <span class="na">plugin=</span><span class="s">&quot;queue&quot;</span> <span class="na">processor=</span><span class="s">&quot;removeDuplication&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nt">&lt;filter</span> <span class="na">reverse=</span><span class="s">&quot;true&quot;</span><span class="nt">&gt;&lt;topic&gt;</span>sys<span class="nt">&lt;/topic&gt;&lt;/filter&gt;</span>
</span><span class='line'><span class="nt">&lt;/stage&gt;</span>
</span><span class='line'><span class="nt">&lt;stage</span> <span class="na">plugin=</span><span class="s">&quot;monitor&quot;</span> <span class="na">processor=</span><span class="s">&quot;default&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nt">&lt;filter&gt;&lt;topic&gt;</span>sys.monitor<span class="nt">&lt;/topic&gt;&lt;/filter&gt;</span>
</span><span class='line'><span class="nt">&lt;/stage&gt;</span>
</span><span class='line'><span class="nt">&lt;stage&gt;</span>
</span><span class='line'>    <span class="nt">&lt;processor</span> <span class="na">plugin=</span><span class="s">&quot;hsuf&quot;</span> <span class="na">processor=</span><span class="s">&quot;byteToHsuf&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>        <span class="nt">&lt;filter&gt;&lt;topic&gt;</span>strategy.server<span class="nt">&lt;/topic&gt;&lt;/filter&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/processor&gt;</span>
</span><span class='line'>    <span class="nt">&lt;processor</span> <span class="na">plugin=</span><span class="s">&quot;strategy&quot;</span> <span class="na">processor=</span><span class="s">&quot;byteToStrategy&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>        <span class="nt">&lt;filter&gt;&lt;topic&gt;</span>strategy.command<span class="nt">&lt;/topic&gt;&lt;/filter&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/processor&gt;</span>
</span><span class='line'>    <span class="nt">&lt;processor</span> <span class="na">plugin=</span><span class="s">&quot;translator&quot;</span> <span class="na">processor=</span><span class="s">&quot;byteToJson&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>        <span class="nt">&lt;filter&gt;&lt;topic&gt;</span>quote<span class="nt">&lt;/topic&gt;&lt;/filter&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/processor&gt;</span>
</span><span class='line'><span class="nt">&lt;/stage&gt;</span>
</span><span class='line'><span class="nt">&lt;stage</span> <span class="na">plugin=</span><span class="s">&quot;strategy&quot;</span> <span class="na">processor=</span><span class="s">&quot;management&quot;</span> <span class="na">env=</span><span class="s">&quot;strategy&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nt">&lt;filter&gt;&lt;topic&gt;</span>strategy.command<span class="nt">&lt;/topic&gt;&lt;/filter&gt;</span>
</span><span class='line'><span class="nt">&lt;/stage&gt;</span>
</span><span class='line'><span class="nt">&lt;stage</span> <span class="na">sequential=</span><span class="s">&quot;false&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nt">&lt;processor</span> <span class="na">plugin=</span><span class="s">&quot;strategy&quot;</span> <span class="na">processor=</span><span class="s">&quot;runner&quot;</span> <span class="na">env=</span><span class="s">&quot;strategy&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>        <span class="nt">&lt;filter</span> <span class="na">reverse=</span><span class="s">&quot;true&quot;</span><span class="nt">&gt;&lt;topic&gt;</span>sys<span class="nt">&lt;/topic&gt;&lt;/filter&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/processor&gt;</span>
</span><span class='line'><span class="nt">&lt;/stage&gt;</span>
</span><span class='line'><span class="nt">&lt;stage&gt;</span>
</span><span class='line'>    <span class="nt">&lt;processor</span> <span class="na">plugin=</span><span class="s">&quot;hsuf&quot;</span> <span class="na">processor=</span><span class="s">&quot;hsufToByte&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>        <span class="nt">&lt;filter&gt;&lt;topic&gt;</span>hsuf<span class="nt">&lt;/topic&gt;&lt;/filter&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/processor&gt;</span>
</span><span class='line'>    <span class="nt">&lt;processor</span> <span class="na">plugin=</span><span class="s">&quot;strategy&quot;</span> <span class="na">processor=</span><span class="s">&quot;strategyToByte&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>        <span class="nt">&lt;filter&gt;&lt;topic&gt;</span>conn<span class="nt">&lt;/topic&gt;&lt;/filter&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/processor&gt;</span>
</span><span class='line'><span class="nt">&lt;/stage&gt;</span>
</span><span class='line'><span class="nt">&lt;stage</span> <span class="na">plugin=</span><span class="s">&quot;bus&quot;</span> <span class="na">processor=</span><span class="s">&quot;send&quot;</span><span class="nt">/&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<h1>结论</h1>

<p>基于开源消息处理和通信框架，基于Java平台研发的分布式交易中间件和消息总线系统，在架构上和技术上都是可行的，该系统使用通用硬件即可达到数据一致性，可用性，超高性能，可伸缩和可扩展。</p>

<h1>参考资料</h1>

<ol>
<li><a href="http://www.reactivemanifesto.org">The Reactive Manifesto</a></li>
<li><a href="http://disruptor.googlecode.com/files/Disruptor-1.0.pdf">Disruptor Technical Paper</a></li>
<li><a href="http://mechanical-sympathy.blogspot.com/">Mechanical sympathy</a></li>
<li><a href="http://zeromq.org">ZeroMQ</a></li>
<li><a href="http://martinfowler.com/eaaDev/EventSourcing.html">Event sourcing</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[响应式编程(Reactive Programming)：事件驱动]]></title>
    <link href="http://liebo.github.io/blog/2014/04/11/xiang-ying-shi-bian-cheng-reactive-programming-%3Ashi-jian-qu-dong/"/>
    <updated>2014-04-11T09:35:00+08:00</updated>
    <id>http://liebo.github.io/blog/2014/04/11/xiang-ying-shi-bian-cheng-reactive-programming-:shi-jian-qu-dong</id>
    <content type="html"><![CDATA[<p>CPU多核架构的流行，以及Node.js等全异步软件平台的出现使得异步编程逐渐走上主流舞台，相应的各种异步框架也逐渐出现</p>

<h3>回调(Callback)</h3>

<p>当我们说到异步的时候，自然而然的就想到Callback，函数调用的结果通过Callback回调返回，在结果返回之前，线程可以继续运行执行其他的操作而不用阻塞。</p>

<p>非常完美，是吗？但是当多个异步操作具有依赖性时，怎么办，这就产生了异步编程中常说的Callback Hell问题，多个Callback嵌套导致代码可读性很差。</p>

<ol>
<li>代码缩进非常难看。</li>
<li>回调代码分散在各处，来回跳跃，流程很不清晰。</li>
<li>状态分散在多个closure中，难于管理。</li>
</ol>


<p>代码可读性差只是表现，深层次的原因还是系统建模方法不对。使用Callback就和面向过程一样，将重心放在了操作本身，只能看到眼前，而不能在一个更高的层次上去纵观整个系统。</p>

<h3>Future和Promise</h3>

<p>Future在Callback的基础上将回调对象化。Future与Callback的区别在于Future引入了完成，未决，错误等标准回调事件，在Future状态改变时以事件的方式通知关注者，这些事件本身就是对象。于是Future将设计者的重点从操作向事件建模方向转变。</p>

<p>事件建模之外，事件在系统中的流动也需要建模，于是就有了Promise，可以将多个事件处理器串联起来，多个依赖的异步操作转化成事件流程的声明，从而一眼就能从代码中看出依赖关系。</p>

<h3>Reactive Extension (RX)</h3>

<p>RX在Future和Promise的基础上更进了一步，将单一的事件处理扩展到多个先后相关的事件流处理。举个例子，鼠标拖拽事件，是由一个MouseDown事件加多个MouseMove事件以及一个MouseUp事件构成，Promise处理这种情况需要处理器具有状态记住拖拽的阶段。RX将MouseDown和MouseUp这些事件的处理标准化，并且将拖拽阶段的这一共享状态从业务处理器中抽离，而固化到事件处理流程中。RX抽象了大量的事件操作，使得我们可以将重心放到事件流程建模中，而不是具体的一个接一个事件的处理。共享状态从处理器中抽离也有利于业务处理器的重用以及并发处理。</p>

<p>综上，响应式编程中的事件驱动，要求</p>

<ol>
<li>对事件建模</li>
<li>对事件流程建模</li>
<li>对事件相关性建模</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[软件开发之道——程序员的坏习惯]]></title>
    <link href="http://liebo.github.io/blog/2014/04/08/ruan-jian-kai-fa-zhi-dao-cheng-xu-yuan-de-pi-xi-guan/"/>
    <updated>2014-04-08T20:44:32+08:00</updated>
    <id>http://liebo.github.io/blog/2014/04/08/ruan-jian-kai-fa-zhi-dao-cheng-xu-yuan-de-pi-xi-guan</id>
    <content type="html"><![CDATA[<p>近两个月兼任移动与桌面客户端的架构工作，与以前喜好单打独斗的程序员们打交道的过程中，发现一些程序员常有的一些不好的习惯</p>

<h3>不重视单元测试，对测试有误解</h3>

<p>开发工程师倾向于完成功能之后，立即交付测试工程师手动测试或者上层调用者测试，测试有问题再打回来修改bug，如果要求交付之前写单元测试，则认为是在阻碍功能交付的进度，仿佛“任何阻碍我尽快的完成功能开发的行为都是与我有不共戴天之仇”。</p>

<p>表面上写单元测试是多花了时间，实际上等发现bug再打回来重写，这中间产生的沟通成本要大得多，于是出现这样的情况：两个星期把一系列功能完成，而真正稳定可发布则要两个月时间，绝大部分时间耗费在测试，修改bug这种来回的扯皮中。</p>

<p>敏捷开发认为单元测试是成本最小的，一个bug在单元测试阶段发现的成本比起功能测试时才发现要小得多。单元测试虽然是一种白盒测试，但是测试点仍然是对象的接口，白盒主要体现在依赖注入上，单元测试的过程本身就是验证接口设计的过程，甚至在TDD里设计本身就是由测试驱动的。单元测试可以细粒度的检测bug，可以把因素锁定在有限的范围内，并最快的速度迭代，比起功能开发完再测试，成本要小一个量级。我们希望看到的是可以持续的交付，两个星期一个迭代完成功能，同时测试也通过。</p>

<p>合理的对象建模，面向接口的设计，Mock注入，Expect框架等测试自动化框架和工具的使用，可以有效的提高测试的效率。</p>

<h3>害怕变化</h3>

<p>在多人协作，模块化开发中，上层应用的开发者希望下层模块把接口提前设计的完美，接口定了之后最好不要有任何变化，否则改动的影响可能会非常大。这个要求其实也无可厚非，但是敏捷开发告诉我们，这种思路是太理想化的，接口也需要迭代过程中不断完善，需求和架构都是在迭代过程中逐渐清晰的。我们设计领域和事件模型，采纳MVC框架，模块化和层次结构设计，依赖注入等等，无非是为了一点，变化的时候改动的成本尽可能小。快速的迭代，细粒度的重构也是减小变化成本的必须。</p>

<p>程序员不仅不要害怕变化，而且要带着积极的心态拥抱变化。</p>

<h3>缺乏安全感</h3>

<p>很多程序员不喜欢讨论内部的设计，而喜欢对外的API接口设计。他们认为如果太过透明，一是侮辱自己的智商，二是影响自己在项目中的不可或缺性，最好把自己的实现功能作为一个黑盒子给别人，只要自己能够最快的把这个黑盒子实现，就是个人能力的体现。这实在是很短视的一种思想，不过考虑到国内软件企业的现状，倒也情有可原，因为最终的考核都是基于工作量和在项目中的不可或缺性。程序员应该有更高的追求，作为一个团队的一员，以科学的方法论指导工作，保证促进团队的整体效率。而作为个人考核的度量则是新的技术解决难题，引进了新的方法提高了效率等，只有不断进步才能体现个人价值。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[双向数据绑定UML类图设计]]></title>
    <link href="http://liebo.github.io/blog/2014/04/05/shuang-xiang-shu-ju-bang-ding-umllei-tu-she-ji/"/>
    <updated>2014-04-05T17:08:02+08:00</updated>
    <id>http://liebo.github.io/blog/2014/04/05/shuang-xiang-shu-ju-bang-ding-umllei-tu-she-ji</id>
    <content type="html"><![CDATA[<p>面向对象设计第一步是设计类的继承结构和类的实例依赖组合关系，而最好的表达莫过于UML类图。</p>

<p>考虑一个支持数据双向绑定的GridView的设计，首先设计ViewModel的类继承和对象关系</p>

<p><img src="http://yuml.me/diagram/nofunky;dir:LR;/class/[BaseViewModel%7C+bind(BaseView%20view);],%20[BaseViewModel]%5E-%3E[CellViewModel],%20[BaseViewModel]%5E-%3E[ListViewModel]" alt="ViewModel类体系" /></p>

<p><img src="http://yuml.me/diagram/nofunky;dir:LR;/class/[ListViewModel]++-0..*%3E[BaseViewModel]" alt="ViewModel对象关系" /></p>

<p>以及View的类体系结构</p>

<p><img src="http://yuml.me/diagram/nofunky;dir:LR;/class/[BaseView%7C+bind(BaseViewModel%20vm);],%20[BaseView]%5E-%3E[ListView],%20[BaseView]%5E-%3E[CellView],%20[ListView]%5E-%3E[LineView],%20[ListView]%5E-%3E[GridView]" alt="View继承体系" /></p>

<p><img src="http://yuml.me/diagram/nofunky;dir:LR;/class/%20[LineView]++-0..*%3E[CellView],%20[GridView]++-0..*%3E[LineView]" alt="View对象结构" /></p>

<p>最后处理双向绑定关系</p>

<p><img src="http://yuml.me/diagram/nofunky;dir:LR;/class/[BaseView]1-1[BaseViewModel],%20[ListView]1-1[ListViewModel],%20[CellView]1-1[CellViewModel]" alt="双向绑定" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[响应式编程(Reactive Programming)：自动恢复的能力(Resilience)]]></title>
    <link href="http://liebo.github.io/blog/2014/04/04/xiang-ying-shi-bian-cheng-reactive-programming-%3Ashi-xiao-hui-fu-resilience/"/>
    <updated>2014-04-04T15:35:19+08:00</updated>
    <id>http://liebo.github.io/blog/2014/04/04/xiang-ying-shi-bian-cheng-reactive-programming-:shi-xiao-hui-fu-resilience</id>
    <content type="html"><![CDATA[<p>传统的应用在处理错误时</p>

<ul>
<li>粒度太粗，出现错误时，整个服务终止，然后做失效恢复，自动化一点的比如集群某一节点失效之后的Failover</li>
<li>粒度太细，出现错误时，在错误出现的位置处理，典型的，比如根据函数返回值做判断。Java中的异常处理虽然可以交给调用堆栈的上级对象方法处理，仍然只能在有限的范围内处理，不能异步处理，而且将正常的应用逻辑和错误处理混在一起。</li>
</ul>


<p>响应式编程要求应用快速响应错误，并快速的自动恢复，不影响业务逻辑的正常运作。这要求将错误也作为一种事件抛出，交给Supervisor角色去异步处理，而正常的业务逻辑与Supervisor是分开的，不会受到影响。把错误作为一等国民对待，对错误建模，在应用设计过程中一开始就考虑错误处理。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[软件开发之道——面向对象设计是方法论]]></title>
    <link href="http://liebo.github.io/blog/2014/04/03/ruan-jian-kai-fa-zhi-dao-mian-xiang-dui-xiang-she-ji-shi-fang-fa-lun/"/>
    <updated>2014-04-03T17:27:58+08:00</updated>
    <id>http://liebo.github.io/blog/2014/04/03/ruan-jian-kai-fa-zhi-dao-mian-xiang-dui-xiang-she-ji-shi-fang-fa-lun</id>
    <content type="html"><![CDATA[<p>有人吐槽面向对象设计过于复杂，只要Design by Contract，Prefer Composition over Inheritance，Loose Couple就可以了。我要说，这样的认识层次还不够高。这就好比，因为红学家把红楼梦整的特玄乎，而认为红楼梦本身不是好作品。</p>

<p>面向对象分析与设计，是一种方法论，是我们认识世界和改造世界的方法的理论。接口，继承，多态，SOLID等等都只是表象，我们需要做的是透过现象看到本质——那就是，不要从一开始就尝试去具体解决一个问题，或者实现一个需求，而是去描述一个问题，即建模。面向对象设计只是众多建模方式的一种，函数式编程以函数为中心建模，状态机以状态和变迁为中心建模，而面向对象以对象为中心建模则是最符合人们对客观世界的认识的。正如做人一样，有自己的世界观作为准则，做事的时候不必拘泥于具体的某个方法。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Android 项目模块化开发]]></title>
    <link href="http://liebo.github.io/blog/2014/04/02/android-xiang-mu-mo-kuai-hua/"/>
    <updated>2014-04-02T21:02:43+08:00</updated>
    <id>http://liebo.github.io/blog/2014/04/02/android-xiang-mu-mo-kuai-hua</id>
    <content type="html"><![CDATA[<p>伴随移动设备的智能化，移动应用呈现出爆发式的增长。当应用多了以后，应用框架也就自然而然的提上日程。框架设计的第一步就是模块化，实现公共模块和应用模块，模块之间通过接口通信，然后才可能去更进一步的考虑依赖注入，MVC框架，领域和事件模型。Android在模块化方面继承了Java的特点，允许以jar包的方式组织和发布模块，不同的是Android必须将jar包打包进apk，不支持从ClassPath动态载入模块。</p>

<p>在Android模块依赖管理有两个经常遇见的问题：</p>

<ol>
<li>为了将依赖的jar打包进apk，不仅仅要将jar加入依赖列表，还需要指定jar是Exportable的。在Eclipse下，要将jar的路径加入Build Path，还需要将其加入Export Path。用maven来进行模块构建以及依赖管理时，要将依赖的项目加入dependencies列表，并且注意scope不能指定为provided。如果打包好的apk在运行时报错，可以分析一下logcat的输出，如果发现NoClassDefFound之类的错误，则说明有一些依赖的包没有Export（另一个引起这个错误的原因是代码混淆没有配置好，这个以后再讨论）。有时候子类的定义没有找到的话，也会报父类找不到，所以需要仔细的看日志，找到根源的类。有时候Eclipse编译出来的apk可用，maven编译的不可用，这个时候可以考虑解压缩apk和反编译dex，找到maven编译的apk缺少的包和类。</li>
<li>有一些依赖的jar包只是编译期需要，而在运行时是不需要的，比如javax开头的包，在Eclipse下，不需要Export，而maven则需要指定其scope为provided。</li>
</ol>


<p>最后，再强调一下，仔细的分析log，不能忽视任何警告和错误信息。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[软件开发之道——演绎思维到归纳思维的转换]]></title>
    <link href="http://liebo.github.io/blog/2014/03/31/ruan-jian-kai-fa-zhi-dao-yan-yi-si-wei-dao-gui-na-si-wei-de-zhuan-huan/"/>
    <updated>2014-03-31T10:35:37+08:00</updated>
    <id>http://liebo.github.io/blog/2014/03/31/ruan-jian-kai-fa-zhi-dao-yan-yi-si-wei-dao-gui-na-si-wei-de-zhuan-huan</id>
    <content type="html"><![CDATA[<p>从面向过程到面向对象是一种思维方式的转变。面向过程是演绎思维，从一般到特殊，是由上而下的解决一个问题；而面向对象是归纳思维，从特殊到一般，是由下而上的描述一个问题</p>

<p>我们可以看到现代软件工程也是逐渐的从演绎向归纳变化：</p>

<ol>
<li>面向过程是演绎思维，因为其关注的是流程，具体的怎样解决一个问题，表现为函数的逻辑组装。
面向对象是归纳思维，其关注的是对象建模，先抽象出共性和对象之间的关系。</li>
<li>同步编程是演绎思维，所谓同步就是一根筋，把问题分解为几个步骤，每一步都依赖于上一步的结果。
异步编程是归纳思维，整个系统通过异步事件驱动，所以要先抽象出事件模型。</li>
<li>瀑布模型是演绎思维，计划式的开发，一开始就关注具体的业务，每一步计划都依赖于上一步的计划，从一开始就希望控制整个过程。
敏捷模型是归纳思维，演进式的开发，要求从一开始归纳出最基本的Task，然后逐渐演化到更具体的业务，其实和面向对象从接口到具现类是一个道理</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Disruptor Illustrated by Metaphor]]></title>
    <link href="http://liebo.github.io/blog/2014/03/29/disruptor-illustrated-by-metaphor/"/>
    <updated>2014-03-29T22:02:36+08:00</updated>
    <id>http://liebo.github.io/blog/2014/03/29/disruptor-illustrated-by-metaphor</id>
    <content type="html"><![CDATA[<h1>What is disruptor</h1>

<p>LMAX disruptor is a high performance alternative to bounded queues for exchanging data between concurrent threads. Disruptor is first applied in financial and messaging systems for its high performance.</p>

<p>Disruptor throughput compared to queue  <br/>
<img src="http://liebo.github.io/images/disruptor/throughput.png" alt="Throughput" /></p>

<p>Latency compared to queue  <br/>
<img src="http://liebo.github.io/images/disruptor/latency.png" alt="Latency" /></p>

<p>Showing mechanical sympathy to modern CPU designs, disruptor is so fast in a parallel and staged environment. Following explains this in detail.</p>

<h1>Parallel Programming</h1>

<p>The best way to explain technology is by metaphor. As is said:</p>

<blockquote><p><p>
Technology is similar, thought behind is the key.
<p></p></blockquote>

<h2>Metaphor in real world</h2>

<p><em>You are the boss of a fast food restaurant, what are you supposed to do to serve more customers? You hire a waitress with fast hands.</em></p>

<p>Waitress with fast hands  <br/>
<img src="http://liebo.github.io/images/disruptor/fasthand.jpg" alt="Fasthand" /></p>

<p><em>However the speed of waitress is limited, so you hire another waitress. Now the two process requests in parallel, and total throughput is doubled.</em></p>

<p>Hire two waitresses  <br/>
<img src="http://liebo.github.io/images/disruptor/morewaitress.gif" alt="Morewaitress" width="500"></p>

<h2>Technology</h2>

<p>Parallel programming is just the same. with a high speed CPU, programs can run fast, result in high throughput and low latency. However CPU speed is limited to several GHZ, so more CPU cores are introduced, and programs can run in parallel.</p>

<p>CPU speed is limited, but the core numbers obey Moore&rsquo;s law  <br/>
<img src="http://liebo.github.io/images/disruptor/moore.jpg" alt="Moore's law" /></p>

<h1>Staged processing</h1>

<h2>Metaphor</h2>

<p><em>Your restaurant grows rapidly, so you must extend your business to more cities, even more countries. As the boss you can not manage all of your employee by yourself, instead you hire managers.</em></p>

<p>an organization is composed of multiple stages  <br/>
<img src="http://liebo.github.io/images/disruptor/organizational_charts.gif" alt="Organization charts" /></p>

<h2>Technology</h2>

<p>Modern CPU has multiple level caches, and the architecture is similar to an organization.</p>

<p>CPU cache contains multiple stages  <br/>
<img src="http://liebo.github.io/images/disruptor/cache.png" alt="CPU cache" /></p>

<h1>Amdahl&rsquo;s law</h1>

<h2>Metaphor</h2>

<p><em>In real world there is all kind of inefficiency, one department may depend on another. That&rsquo;s why management theories exists.</em></p>

<h2>Technology</h2>

<p>In a program, how can we optimize process in such a parallel and staged environment?</p>

<p><strong>Amdahl&rsquo;s law</strong></p>

<p>The speedup of a program using multiple processors in parallel computing is limited by the time needed for the sequential fraction of the program. If %5 of the program cannot compute in parallel, the speedup can only reach 20 times no matter how many processors there are.</p>

<p>Amdahl&rsquo;s law  <br/>
<img src="http://liebo.github.io/images/disruptor/amdahl.png" alt="Amdahl's law" /></p>

<p>To remove inefficiency, just find the bottleneck that can not run in parallel, namely avoid shared resources.</p>

<h1>Optimization: Batch message</h1>

<p>The first bottleneck is main memory access, which is expensive.</p>

<h2>Metaphor</h2>

<p><em>Manager collect status of employees, but they do not send to the boss you one by one, instead they wait until all the status are collected, and send to you in a batch.</em></p>

<h2>Technology</h2>

<p>Similarly, CPU cache is split to cache lines, and batch read data from main memory.</p>

<p>Disruptor use ring buffer to place objects padding together in memory so as to avoid false sharing and cache miss.</p>

<p>Ring buffer  <br/>
<img src="http://liebo.github.io/images/disruptor/ringbuffer.jpg" alt="ringbuffer" /></p>

<h1>Optimization: Lock free synchronization</h1>

<p>Another bottleneck is shared locks.</p>

<h2>Metaphor</h2>

<p><em>People manager and product manager both manage employees. They can exchange status of employees directly since their offices are close to each other.</em></p>

<h2>Technology</h2>

<p>Synchronization for shared resource is expensive.</p>

<ol>
<li>Lock: involves context switch, which is quite expensive.</li>
<li>CAS: lock instruction pipeline and complex to program.</li>
</ol>


<p>lock penalty  <br/>
<img src="http://liebo.github.io/images/disruptor/lockpenalty.png" alt="Lock penalty" /></p>

<p>Disruptor use lock free memory barrier to synchronize sequence of ring buffer. Two cores in CPU talk to each other directly via memory barrier to exchange resource state, so as to avoid accessing shared locks.</p>

<p>memory barrier  <br/>
<img src="http://liebo.github.io/images/disruptor/memorybarrier.png" alt="Memory barrier" /></p>

<h1>Reference</h1>

<ol>
<li><a href="http://lmax-exchange.github.io/disruptor/">LMAX disruptor on github</a></li>
<li><a href="http://disruptor.googlecode.com/files/Disruptor-1.0.pdf">Disruptor Technical Paper</a></li>
<li><a href="http://mechanical-sympathy.blogspot.com/">Mechanical sympathy</a></li>
<li><a href="http://www.infoq.com/presentations/LMAX">Disruptor presentation@QCON</a></li>
<li><a href="http://en.wikipedia.org/wiki/Moore_Law">Moore&rsquo;s law@Wikipedia</a></li>
<li><a href="http://en.wikipedia.org/wiki/Amdahl's_law">Amdahl&rsquo;s law@Wikipedia</a></li>
<li><a href="http://en.wikipedia.org/wiki/Circular_buffer">Ring buffer@Wikipedia</a></li>
<li><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;ved=0CDAQFjAA&amp;url=http%3A%2F%2Fwww.rdrop.com%2F~paulmck%2Fscalability%2Fpaper%2Fwhymb.2009.04.05a.pdf&amp;ei=cJfUUrS5BM2CogSWy4DIAw&amp;usg=AFQjCNHA6MjCwoLJFe5dQTye_uI9dimTNg&amp;sig2=tU3Q4l6EbVsTMf7fOqH5hA">Memory Barriers: a Hardware View for Software Hackers</a></li>
</ol>

]]></content>
  </entry>
  
</feed>
